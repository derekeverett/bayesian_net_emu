{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Neural Network for Computer Model Emulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using idf = 0 : Grad\n",
      "SystemsInfo = \n",
      "{'Pb-Pb-2760': {'proj': 'Pb', 'targ': 'Pb', 'sqrts': 2760, 'main_design_file': 'production_designs/500pts/design_pts_Pb_Pb_2760_production/design_points_main_PbPb-2760.dat', 'main_range_file': 'production_designs/500pts/design_pts_Pb_Pb_2760_production/design_ranges_main_PbPb-2760.dat', 'validation_design_file': 'production_designs/500pts/design_pts_Pb_Pb_2760_production/design_points_validation_PbPb-2760.dat', 'validation_range_file': 'production_designs/500pts/design_pts_Pb_Pb_2760_production//design_ranges_validation_PbPb-2760.dat', 'main_events_dir': 'model_calculations/production_500pts_Pb_Pb_2760/Events/main', 'validation_events_dir': 'model_calculations/production_500pts_Pb_Pb_2760/Events/validation', 'main_obs_file': 'model_calculations/production_500pts_Pb_Pb_2760/Obs/main.dat', 'validation_obs_file': 'model_calculations/production_500pts_Pb_Pb_2760/Obs/validation.dat', 'n_design': 500, 'n_validation': 100, 'design_remove_idx': [289, 483, 324, 326, 459, 429, 334, 462, 242, 341, 406, 440, 377, 123, 447], 'npc': 10, 'MAP_obs_file': 'model_calculations/MAP/Grad/Obs/obs_Pb-Pb-2760.dat'}, 'Au-Au-200': {'proj': 'Au', 'targ': 'Au', 'sqrts': 200, 'main_design_file': 'production_designs/500pts/design_pts_Au_Au_200_production/design_points_main_AuAu-200.dat', 'main_range_file': 'production_designs/500pts/design_pts_Au_Au_200_production/design_ranges_main_AuAu-200.dat', 'validation_design_file': 'production_designs/500pts/design_pts_Au_Au_200_production/design_points_validation_AuAu-200.dat', 'validation_range_file': 'production_designs/500pts/design_pts_Au_Au_200_production//design_ranges_validation_AuAu-200.dat', 'main_events_dir': 'model_calculations/production_500pts_Au_Au_200/Events/main', 'validation_events_dir': 'model_calculations/production_500pts_Au_Au_200/Events/validation', 'main_obs_file': 'model_calculations/production_500pts_Au_Au_200/Obs/main.dat', 'validation_obs_file': 'model_calculations/production_500pts_Au_Au_200/Obs/validation.dat', 'n_design': 500, 'n_validation': 100, 'design_remove_idx': [289, 483, 324, 326, 459, 429, 334, 462, 242, 341, 406, 440, 377, 123, 447], 'npc': 6, 'MAP_obs_file': 'model_calculations/MAP/Grad/Obs/obs_Au-Au-200.dat'}}\n",
      "The active observable list for calibration: {'Pb-Pb-2760': ['dNch_deta', 'dET_deta', 'dN_dy_pion', 'dN_dy_kaon', 'dN_dy_proton', 'mean_pT_pion', 'mean_pT_kaon', 'mean_pT_proton', 'pT_fluct', 'v22', 'v32', 'v42'], 'Au-Au-200': ['dN_dy_pion', 'dN_dy_kaon', 'mean_pT_pion', 'mean_pT_kaon', 'v22', 'v32']}\n",
      "Loading Pb-Pb-2760 main calculations from model_calculations/production_500pts_Pb_Pb_2760/Obs/main.dat\n",
      "model_data.shape = (500,)\n",
      "Design points which will be deleted from training : [289, 483, 324, 326, 459, 429, 334, 462, 242, 341, 406, 440, 377, 123, 447]\n",
      "Loading Pb-Pb-2760 MAP calculations from model_calculations/MAP/Grad/Obs/obs_Pb-Pb-2760.dat\n",
      "No MAP calculations found for system Pb-Pb-2760\n",
      "Loading Au-Au-200 main calculations from model_calculations/production_500pts_Au_Au_200/Obs/main.dat\n",
      "model_data.shape = (500,)\n",
      "Design points which will be deleted from training : [289, 483, 324, 326, 459, 429, 334, 462, 242, 341, 406, 440, 377, 123, 447]\n",
      "Loading Au-Au-200 MAP calculations from model_calculations/MAP/Grad/Obs/obs_Au-Au-200.dat\n",
      "No MAP calculations found for system Au-Au-200\n"
     ]
    }
   ],
   "source": [
    "from calculations_load import *\n",
    "from configurations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the observables list\n",
    "\n",
    "nobs        =  0\n",
    "observables =  []\n",
    "obs_name    =  []\n",
    "\n",
    "for obs, cent_list in obs_cent_list['Pb-Pb-2760'].items():\n",
    "    if obs not in active_obs_list['Pb-Pb-2760']:\n",
    "        continue\n",
    "    observables.append(obs)\n",
    "    n = np.array(cent_list).shape[0]\n",
    "    for i in cent_list:\n",
    "        obs_name.append(f'{obs}_{i}')\n",
    "    #self._slices[obs] = slice(self.nobs, self.nobs + n)\n",
    "    nobs += n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the directories for model design and outputs\n",
    "#run this cell only once, or else it will hang!\n",
    "#! sh prepare.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Computer Model inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_str = 'Pb-Pb-2760'\n",
    "design_file = 'production_designs/500pts/design_pts_Pb_Pb_2760_production/design_points_main_PbPb-2760.dat'\n",
    "design = pd.read_csv(design_file)\n",
    "design = design.drop(\"idx\", axis=1)\n",
    "\n",
    "#delete bad design points\n",
    "drop_indices = list(delete_design_pts_set)\n",
    "design = design.drop(drop_indices)\n",
    "\n",
    "#choose features (inputs)\n",
    "#feature_cols = ['norm', 'trento_p'] #specific choices\n",
    "feature_cols = design.keys().values #all of them \n",
    "n_features = len(feature_cols)\n",
    "\n",
    "X = design[feature_cols]\n",
    "\n",
    "n_design = SystemsInfo[\"Pb-Pb-2760\"][\"n_design\"]\n",
    "npt = n_design - len(delete_design_pts_set)\n",
    "obs = 'dNch_deta' #choose the observable we want to emulate\n",
    "\n",
    "Y = np.array([])\n",
    "\n",
    "for pt in range(npt):\n",
    "    for obs in active_obs_list['Pb-Pb-2760']:\n",
    "        Y = np.append( Y, trimmed_model_data[system_str][pt, idf][obs]['mean'][:], axis=0)\n",
    "Y = Y.reshape(X.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape : (485, 17)\n",
      "Y.shape : (485, 110)\n"
     ]
    }
   ],
   "source": [
    "print( \"X.shape : \"+ str(X.shape) )\n",
    "print( \"Y.shape : \"+ str(Y.shape) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the inputs and outputs into a training and testing set\n",
    "\n",
    "Then, scaling all of the inputs and outputs to (0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2)\n",
    "\n",
    "#X_scaler = StandardScaler().fit(X_train)\n",
    "#Y_scaler = StandardScaler().fit(Y_train)\n",
    "X_scaler = MinMaxScaler(feature_range=(-1, 1)).fit(X_train)\n",
    "Y_scaler = MinMaxScaler(feature_range=(-1, 1)).fit(Y_train)\n",
    "\n",
    "X_train_sc = X_scaler.transform(X_train)\n",
    "X_test_sc = X_scaler.transform(X_test)\n",
    "\n",
    "Y_train_sc = Y_scaler.transform(Y_train)\n",
    "Y_test_sc = Y_scaler.transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The cell below constructs the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "add() got an unexpected keyword argument 'training'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-88fc3be4d900>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tanh'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tanh'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sensitivity/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: add() got an unexpected keyword argument 'training'"
     ]
    }
   ],
   "source": [
    "# n_hidden = 0 # number of hidden layers\n",
    "\n",
    "# model = keras.Sequential()\n",
    "# model.add(layers.Dense(50, input_dim=X.shape[1], activation='tanh'))\n",
    "# for n in range(n_hidden):\n",
    "#     model.add(layers.Dense(20, activation='tanh'))\n",
    "# model.add(layers.Dropout(0.5))\n",
    "# model.add(layers.Dense(Y.shape[1], activation='tanh'))\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Input, Dense, Dropout ,Conv1D\n",
    "def model_fn(ly1_units=20,activation_1='sigmoid',activation_2='tanh',ly2_units=20,activation_3='tanh',\\\n",
    "             dropout_rate1 = 0.1,dropout_rate2 = 0.1,loss_fn=\"huber_loss\", krnl_sz=5,\\\n",
    "            optimizer='adam'):\n",
    "    inputs = Input(shape=(X.shape[1],1))\n",
    "    x = Dense(ly1_units, activation=activation_1)(inputs)\n",
    "   # print(x.shape)\n",
    "    x=  Conv1D(filters=1,kernel_size=krnl_sz)(x)\n",
    "    x= Flatten()(x)\n",
    "    x = Dropout(dropout_rate1)(x, training=True)\n",
    "    x = Dense(ly2_units, activation=activation_2)(x)\n",
    "    x = Dropout(dropout_rate2)(x, training=True)\n",
    "    x = Dense(Y.shape[1], activation=activation_3)(x)\n",
    "    outputs = x\n",
    "    model = Model(inputs, outputs)\n",
    "#model.compile(loss=\"mean_squared_error\", optimizer='adam')\n",
    "    model.compile(loss=loss_fn, optimizer=optimizer)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_49 (InputLayer)        (None, 17, 1)             0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 17, 20)            40        \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 13, 1)             101       \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 20)                280       \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 110)               2310      \n",
      "=================================================================\n",
      "Total params: 2,731\n",
      "Trainable params: 2,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# compile the keras model\n",
    "#model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "model=model_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=np.expand_dims(X_train_sc,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 27648 candidates, totalling 55296 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   23.4s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   23.9s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:   24.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   24.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   25.6s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:   28.9s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:   29.4s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   44.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   45.0s\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:   47.8s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:   49.0s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:   50.3s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   50.5s\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:   54.7s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  39 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  43 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:  1.9min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-156-68aa398f12ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                   loss_fn=loss_fn,optimizer=optimizer,batch_size=batch_size,krnl_sz=krnl_sz)\n\u001b[1;32m     14\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_sc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/sensitivity/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sensitivity/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sensitivity/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sensitivity/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sensitivity/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sensitivity/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sensitivity/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sensitivity/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "ly_units=[50,100,200,500]\n",
    "activation_1=['sigmoid','tanh']\n",
    "activation_2=['linear','tanh']\n",
    "dropout_rate = [0.2, 0.3, 0.5]\n",
    "krnl_sz=[5,10,20,40]\n",
    "loss_fn=[\"mse\",\"huber_loss\"]\n",
    "optimizer=['adam']\n",
    "batch_size=[10, 20, 50]\n",
    "estimator=tf.keras.wrappers.scikit_learn.KerasRegressor(build_fn=model_fn)\n",
    "param_grid = dict(ly1_units=ly_units,ly2_units=ly_units,activation_1=activation_1, activation_2=activation_1,\\\n",
    "                activation_3=activation_2,dropout_rate1=dropout_rate,dropout_rate2=dropout_rate,\\\n",
    "                  loss_fn=loss_fn,optimizer=optimizer,batch_size=batch_size,krnl_sz=krnl_sz)\n",
    "grid = GridSearchCV(estimator=estimator, param_grid=param_grid, n_jobs=-1, cv=2, scoring='r2',verbose=20)\n",
    "grid_result = grid.fit(test, Y_train_sc,epochs=300,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_=grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#{'activation_1': 'tanh',\n",
    "#  'activation_2': 'tanh',\n",
    "#  'batch_size': 10,\n",
    "#  'dropout_rate': 0.2,\n",
    "#  'loss_fn': 'mse',\n",
    "#  'ly1_units': 200,\n",
    "#  'optimizer': 'adam'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_.pop('batch_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b=model_fn(**best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b.fit(X_train_sc, Y_train_sc, epochs=500, batch_size=10,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "predictions = []\n",
    "sample_size = 1000\n",
    "for t in range(sample_size):\n",
    "    predictions.append(model.predict(X_test_sc))\n",
    "   # pred_array = np.array(predictions)\n",
    "   # print(pred_array.shape)\n",
    "#prediction_df = pd.DataFrame()\n",
    "#prediction_std= pd.DataFrame()\n",
    "pred_array = np.array(predictions)\n",
    "prediction_df= np.mean(pred_array,axis=0)\n",
    "prediction_sd= np.std(pred_array,axis=0)\n",
    "#prediction_df['std'] = pred_array.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = np.linspace(-1, 1, 100)\n",
    "obs_indices = [60, 61, 68, 69, 15, 85]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 7))\n",
    "fig.suptitle('Prediction vs truth with 2 Sigma uncertinity', fontsize=16)\n",
    "fig.text(0.5, 0.04, 'Truth', ha='center')\n",
    "fig.text(0.04, 0.5, 'Prediction', va='center', rotation='vertical')\n",
    "for i, obs_ind in enumerate(obs_indices):\n",
    "    ax = axes.flatten()[i]\n",
    "    ax.set_title(obs_name[obs_ind])\n",
    "    ax.plot(truth, truth, c='r', lw=3, zorder=-1)\n",
    "    ax.errorbar(Y_test_sc[:, obs_ind], prediction_df[:, obs_ind],yerr=2*prediction_sd[:,obs_ind],alpha=0.5,fmt='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "coefficient_of_dermination = r2_score(Y_test_sc,prediction_df)\n",
    "coefficient_of_dermination_tf = r2_score(Y_scaler.inverse_transform(Y_test_sc),Y_scaler.inverse_transform(prediction_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'coefficient_of_dermination transformed_observable space {coefficient_of_dermination_tf}, normalized space {coefficient_of_dermination}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def root_mean_squre_percentage_error(y_true, y_pred,feature_loc): \n",
    "    y_true, y_pred = Y_scaler.inverse_transform(y_true)[:,feature_loc], Y_scaler.inverse_transform(y_pred)[:,feature_loc]\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred)/ y_true))) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import mean_squared_error\n",
    "def plot_rmse_bp(observable='dN_dy_pion'):\n",
    "    # Get all the observables list\n",
    "    prediction_df_bp=pd.DataFrame()\n",
    "    nobs        =  0\n",
    "    observables =  []\n",
    "    obs_name    =  []\n",
    "    prediction_rmse=pd.DataFrame()\n",
    "    for obs, cent_list in obs_cent_list['Pb-Pb-2760'].items():\n",
    "        nobs += nobs\n",
    "        if obs !=observable:\n",
    "            continue\n",
    "        for k,i in enumerate(cent_list):\n",
    "            obs_name.append(f'{obs}_{i}')\n",
    "            new=prediction_df[:,nobs+k]-Y_test_sc[:,nobs+k]\n",
    "        #self._slices[obs] = slice(self.nobs, self.nobs + n)\n",
    "          #  print(np.mean(-Y_test_sc[:,i],axis=0))\n",
    "           # print(prediction_df[:,i]-Y_test_sc[:,i])\n",
    "            prediction_df_bp[f'{i}']=new\n",
    "            #print(mean_squared_error(prediction_df[:,nobs+k],Y_test_sc[:,nobs+k]))\n",
    "            prediction_rmse[f'{i}']=[root_mean_squre_percentage_error(Y_test_sc,prediction_df,nobs+k)]\n",
    "          #  prediction_df_bp[i]=\n",
    "          #  print(prediction_df_bp.shape)\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(20, 10))\n",
    "    for i in [0,1]:\n",
    "        ax=axes.flatten()[i]\n",
    "        if (i==0):\n",
    "            boxplot = prediction_df_bp.boxplot(rot=90,ax=ax,showfliers=False)\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_ylabel('Normalized Residuals',fontsize=15)\n",
    "        if (i==1):\n",
    "            ax.scatter(prediction_rmse.keys(),prediction_rmse.iloc[0])\n",
    "            ax.set_xticklabels(labels=prediction_rmse.keys(), rotation=90, ha='right')\n",
    "            ax.set_ylabel('RMS % error',fontsize=15)\n",
    "            #scatter_plt = prediction_rmse.plot.scatter(rot=90,ax=ax)\n",
    "    fig.text(0.04, 0.5, observable, va='center', rotation='vertical',fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "for obs in active_obs_list['Pb-Pb-2760']:\n",
    "    plot_rmse_bp(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
