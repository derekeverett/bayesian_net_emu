{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using idf = 0 : Grad\n",
      "SystemsInfo = \n",
      "{'Pb-Pb-2760': {'proj': 'Pb', 'targ': 'Pb', 'sqrts': 2760, 'main_design_file': 'production_designs/500pts/design_pts_Pb_Pb_2760_production/design_points_main_PbPb-2760.dat', 'main_range_file': 'production_designs/500pts/design_pts_Pb_Pb_2760_production/design_ranges_main_PbPb-2760.dat', 'validation_design_file': 'production_designs/500pts/design_pts_Pb_Pb_2760_production/design_points_validation_PbPb-2760.dat', 'validation_range_file': 'production_designs/500pts/design_pts_Pb_Pb_2760_production//design_ranges_validation_PbPb-2760.dat', 'labels': ['$N$[$2.76$TeV]', '$p$', '$\\\\sigma_k$', '$w$ [fm]', '$d_{\\\\mathrm{min}}$ [fm]', '$\\\\tau_R$ [fm/$c$]', '$\\\\alpha$', '$T_{\\\\eta,\\\\mathrm{kink}}$ [GeV]', '$a_{\\\\eta,\\\\mathrm{low}}$ [GeV${}^{-1}$]', '$a_{\\\\eta,\\\\mathrm{high}}$ [GeV${}^{-1}$]', '$(\\\\eta/s)_{\\\\mathrm{kink}}$', '$(\\\\zeta/s)_{\\\\max}$', '$T_{\\\\zeta,c}$ [GeV]', '$w_{\\\\zeta}$ [GeV]', '$\\\\lambda_{\\\\zeta}$', '$b_{\\\\pi}$', '$T_{\\\\mathrm{sw}}$ [GeV]'], 'main_events_dir': 'model_calculations/production_500pts_Pb_Pb_2760/Events/main', 'validation_events_dir': 'model_calculations/production_500pts_Pb_Pb_2760/Events/validation', 'main_obs_file': 'model_calculations/production_500pts_Pb_Pb_2760/Obs/main.dat', 'validation_obs_file': 'model_calculations/production_500pts_Pb_Pb_2760/Obs/validation.dat', 'n_design': 500, 'n_validation': 100, 'design_remove_idx': [289, 483, 324, 326, 459, 429, 334, 462, 242, 341, 406, 440, 377, 123, 447], 'npc': 10, 'MAP_obs_file': 'model_calculations/MAP/Grad/Obs/obs_Pb-Pb-2760.dat'}}\n",
      "Performing emulator validation type ...\n",
      "... independent-validation, using validation_pt = 0\n",
      "The active observable list for calibration: {'Pb-Pb-2760': ['dNch_deta', 'dET_deta', 'dN_dy_pion', 'dN_dy_kaon', 'dN_dy_proton', 'mean_pT_pion', 'mean_pT_kaon', 'mean_pT_proton', 'pT_fluct', 'v22', 'v32', 'v42']}\n",
      "Loading Pb-Pb-2760 main calculations from model_calculations/production_500pts_Pb_Pb_2760/Obs/main.dat\n",
      "model_data.shape = (500,)\n",
      "Design points which will be deleted from training : [289, 483, 324, 326, 459, 429, 334, 462, 242, 341, 406, 440, 377, 123, 447]\n",
      "Loading Pb-Pb-2760 validation calculations from model_calculations/production_500pts_Pb_Pb_2760/Obs/validation.dat\n",
      "validation_data.shape = (100,)\n",
      "Loading Pb-Pb-2760 MAP calculations from model_calculations/MAP/Grad/Obs/obs_Pb-Pb-2760.dat\n",
      "MAP_data.shape = (1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dananjayaliyanage/miniconda3/envs/sensitivity/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "sns.set()\n",
    "import sys\n",
    "from numpy.linalg import inv\n",
    "# Provide the path to the sims emulator validation source code base.\n",
    "sys.path.insert(0, '/Users/dananjayaliyanage/git/emulator-validation/src')\n",
    "#sys.path.insert(0, '/Users/dananjayaliyanage/git/emulator-validation/emulator')\n",
    "from configurations import load_design, transform_design\n",
    "#from bayes_mcmc import *\n",
    "from emulator import *\n",
    "from calculations_load import trimmed_model_data,validation_data\n",
    "from bins_and_cuts import *\n",
    "import matplotlib.patches as mpatches\n",
    "#from bayes_exp import Y_exp_data\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dananjayaliyanage/miniconda3/envs/sensitivity/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/dananjayaliyanage/miniconda3/envs/sensitivity/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/dananjayaliyanage/miniconda3/envs/sensitivity/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/dananjayaliyanage/miniconda3/envs/sensitivity/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/dananjayaliyanage/miniconda3/envs/sensitivity/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/dananjayaliyanage/miniconda3/envs/sensitivity/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/dananjayaliyanage/miniconda3/envs/sensitivity/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/dananjayaliyanage/miniconda3/envs/sensitivity/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/dananjayaliyanage/miniconda3/envs/sensitivity/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/dananjayaliyanage/miniconda3/envs/sensitivity/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/dananjayaliyanage/miniconda3/envs/sensitivity/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/dananjayaliyanage/miniconda3/envs/sensitivity/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all model parametr names to an array\n",
    "\n",
    "model_labels= ['norm','trento_p','sigma_k','nucleon_width',\n",
    "               'dmin3','tau_R','alpha','shear_relax_time_factor','Tswitch']\n",
    "\n",
    "viscous_eta=[r'$\\eta \\,$ at T={} GeV'.format(round(i,2)) \n",
    "             for i in np.linspace(0.135,0.4,10)]\n",
    "\n",
    "viscous_bulk=[r'$\\zeta \\,$ at T={} GeV'.format(round(i,2))\n",
    "              for i in np.linspace(0.135,0.4,10)]\n",
    "\n",
    "all_model_labels=model_labels+viscous_eta+viscous_bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the observables list\n",
    "\n",
    "nobs        =  0\n",
    "observables =  []\n",
    "obs_name    =  []\n",
    "\n",
    "for obs, cent_list in obs_cent_list['Pb-Pb-2760'].items():\n",
    "    observables.append(obs)\n",
    "    n = np.array(cent_list).shape[0]\n",
    "    for i in cent_list:\n",
    "        obs_name.append(f'{obs}_{i}')\n",
    "    #self._slices[obs] = slice(self.nobs, self.nobs + n)\n",
    "    nobs += n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_Obs shape[Ndesign, Nobs] = (485, 123)\n"
     ]
    }
   ],
   "source": [
    "# Get the simulation results corresponding to design points\n",
    "idf=0\n",
    "Y   =  []\n",
    "for ipt, data in enumerate(trimmed_model_data['Pb-Pb-2760']):\n",
    "    row = np.array([])\n",
    "    for obs in observables:\n",
    "        values = np.array(data[idf][obs]['mean'])\n",
    "        if np.isnan(values).sum() > 0:\n",
    "            print(\"WARNING! FOUND NAN IN MODEL DATA WHILE BUILDING EMULATOR!\")\n",
    "            print(\"Design pt = \" + str(pt) + \"; Obs = \" + obs)\n",
    "        row = np.append(row, values)\n",
    "    Y.append(row)\n",
    "Y = np.array(Y)\n",
    "print(\"Y_Obs shape[Ndesign, Nobs] = \" + str(Y.shape))\n",
    "#pca = PCA(copy=False, whiten=True, svd_solver='full')\n",
    "#Z=pca.fit_transform(SS.fit_transform(Y))[:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading main points from production_designs/500pts/design_pts_Pb_Pb_2760_production/design_points_main_PbPb-2760.dat\n",
      "Loading main ranges from production_designs/500pts/design_pts_Pb_Pb_2760_production/design_ranges_main_PbPb-2760.dat\n",
      "Summary of design : \n",
      "Note : Transforming design of viscosities\n",
      "Warning! Deleting 15 points from data\n"
     ]
    }
   ],
   "source": [
    "design, design_max, design_min, labels = prepare_emu_design('Pb-Pb-2760')\n",
    "if len(delete_design_pts_set) > 0:\n",
    "    print(\"Warning! Deleting \"\n",
    "          + str(len(delete_design_pts_set)) + \" points from data\")\n",
    "    design = np.delete(design, list(delete_design_pts_set), 0)\n",
    "alldesign=[design, design_max, design_min,labels]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! FOUND NAN IN MODEL DATA WHILE BUILDING EMULATOR!\n",
      "Design pt = 36; Obs = v42\n",
      "WARNING! FOUND NAN IN MODEL DATA WHILE BUILDING EMULATOR!\n",
      "Design pt = 43; Obs = v42\n",
      "WARNING! FOUND NAN IN MODEL DATA WHILE BUILDING EMULATOR!\n",
      "Design pt = 47; Obs = v42\n",
      "WARNING! FOUND NAN IN MODEL DATA WHILE BUILDING EMULATOR!\n",
      "Design pt = 73; Obs = v42\n",
      "WARNING! FOUND NAN IN MODEL DATA WHILE BUILDING EMULATOR!\n",
      "Design pt = 96; Obs = v42\n",
      "Y_Val_Obs shape[Ndesign, Nobs] = (100, 123)\n"
     ]
    }
   ],
   "source": [
    "# Get the simulation results for validaton corresponding to design points\n",
    "YV=[]\n",
    "nanrows=[]\n",
    "for ipt, data in enumerate(validation_data['Pb-Pb-2760']):\n",
    "    row = np.array([])\n",
    "    for obs in observables:\n",
    "        values = np.array(data[idf][obs]['mean'])\n",
    "        if np.isnan(values).sum() > 0:\n",
    "            print(\"WARNING! FOUND NAN IN MODEL DATA WHILE BUILDING EMULATOR!\")\n",
    "            print(\"Design pt = \" + str(ipt) + \"; Obs = \" + obs)\n",
    "            nanrows.append(ipt)\n",
    "        row = np.append(row, values)\n",
    "    YV.append(row)\n",
    "YV = np.array(YV)\n",
    "nanrows=np.array(nanrows)\n",
    "print(\"Y_Val_Obs shape[Ndesign, Nobs] = \" + str(YV.shape))\n",
    "#pca = PCA(copy=False, whiten=True, svd_solver='full')\n",
    "#Z=pca.fit_transform(SS.fit_transform(Y))[:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "todeleterows=np.concatenate((nanrows,delete_design_pts_validation_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([36, 43, 47, 73, 96, 10, 68, 93])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "todeleterows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 123)\n",
      "after truccation shape(92, 123)\n"
     ]
    }
   ],
   "source": [
    "print(YV.shape)\n",
    "YV_truncates=np.delete(YV,obj=todeleterows,axis=0)\n",
    "print(f'after truccation shape{YV_truncates.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation points from production_designs/500pts/design_pts_Pb_Pb_2760_production/design_points_validation_PbPb-2760.dat\n",
      "Loading validation ranges from production_designs/500pts/design_pts_Pb_Pb_2760_production//design_ranges_validation_PbPb-2760.dat\n",
      "Summary of design : \n",
      "Warning! Deleting 8 points from data\n",
      "Shape of validation design array (92, 17)\n"
     ]
    }
   ],
   "source": [
    "design_v,dsgn_max_v,dsgn_min_v,design_v_lbls=load_design(system_str='Pb-Pb-2760', pset='validation')\n",
    "if len(todeleterows) > 0:\n",
    "    print(\"Warning! Deleting \" + str(len(todeleterows)) + \" points from data\")\n",
    "    design_v= np.delete(np.array(design_v), obj=todeleterows, axis=0)\n",
    "    print(f'Shape of validation design array {design_v.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_v=transform_design(design_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model / data parametaers\n",
    "#num_classes = 10\n",
    "input_shape = (29,1)\n",
    "x_train= design.reshape(485,29,1)\n",
    "y_train= Y\n",
    "x_test=design_v.reshape(92,29,1)\n",
    "y_test=YV_truncates\n",
    "# the data, split between train and test sets\n",
    "#(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (485, 29, 1)\n",
      "485 train samples\n",
      "92 test samples\n"
     ]
    }
   ],
   "source": [
    "# Scale images to the [0, 1] range\n",
    "#x_train = x_train.astype(\"float32\") / 255\n",
    "#x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "#x_train = np.expand_dims(x_train, -1)\n",
    "#x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "#y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/dananjayaliyanage/miniconda3/envs/sensitivity/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 27, 100)           400       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 9, 100)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 7, 50)             15050     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 2, 50)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 123)               12423     \n",
      "=================================================================\n",
      "Total params: 27,873\n",
      "Trainable params: 27,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv1D(100, kernel_size=3, activation=\"relu\"),\n",
    "        layers.MaxPooling1D(pool_size=3),\n",
    "        layers.Conv1D(50, kernel_size=3, activation=\"relu\"),\n",
    "        layers.MaxPooling1D(pool_size=3),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(123, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 436 samples, validate on 49 samples\n",
      "Epoch 1/30\n",
      "436/436 [==============================] - 0s 566us/sample - loss: 250587.4243 - acc: 0.0528 - val_loss: 257169.6562 - val_acc: 0.0000e+00\n",
      "Epoch 2/30\n",
      "436/436 [==============================] - 0s 88us/sample - loss: 250581.7577 - acc: 0.1284 - val_loss: 257159.9531 - val_acc: 0.0000e+00\n",
      "Epoch 3/30\n",
      "436/436 [==============================] - 0s 70us/sample - loss: 250571.9258 - acc: 0.4495 - val_loss: 257147.2812 - val_acc: 1.0000\n",
      "Epoch 4/30\n",
      "436/436 [==============================] - 0s 66us/sample - loss: 250563.5461 - acc: 0.8922 - val_loss: 257145.4219 - val_acc: 1.0000\n",
      "Epoch 5/30\n",
      "436/436 [==============================] - 0s 73us/sample - loss: 250561.4269 - acc: 0.9885 - val_loss: 257145.4219 - val_acc: 1.0000\n",
      "Epoch 6/30\n",
      "436/436 [==============================] - 0s 62us/sample - loss: 250561.0664 - acc: 1.0000 - val_loss: 257145.4062 - val_acc: 1.0000\n",
      "Epoch 7/30\n",
      "436/436 [==============================] - 0s 65us/sample - loss: 250561.0007 - acc: 1.0000 - val_loss: 257145.4219 - val_acc: 1.0000\n",
      "Epoch 8/30\n",
      "436/436 [==============================] - 0s 71us/sample - loss: 250561.0011 - acc: 0.9977 - val_loss: 257145.4062 - val_acc: 1.0000\n",
      "Epoch 9/30\n",
      "436/436 [==============================] - 0s 61us/sample - loss: 250560.9805 - acc: 1.0000 - val_loss: 257145.4062 - val_acc: 1.0000\n",
      "Epoch 10/30\n",
      "436/436 [==============================] - 0s 63us/sample - loss: 250560.9962 - acc: 0.9977 - val_loss: 257145.4219 - val_acc: 1.0000\n",
      "Epoch 11/30\n",
      "436/436 [==============================] - 0s 64us/sample - loss: 250560.9731 - acc: 1.0000 - val_loss: 257145.4062 - val_acc: 1.0000\n",
      "Epoch 12/30\n",
      "436/436 [==============================] - 0s 61us/sample - loss: 250560.9911 - acc: 1.0000 - val_loss: 257145.4219 - val_acc: 1.0000\n",
      "Epoch 13/30\n",
      "436/436 [==============================] - 0s 60us/sample - loss: 250560.9705 - acc: 1.0000 - val_loss: 257145.4219 - val_acc: 1.0000\n",
      "Epoch 14/30\n",
      "436/436 [==============================] - 0s 61us/sample - loss: 250560.9674 - acc: 1.0000 - val_loss: 257145.4062 - val_acc: 1.0000\n",
      "Epoch 15/30\n",
      "436/436 [==============================] - 0s 60us/sample - loss: 250560.9612 - acc: 1.0000 - val_loss: 257145.4219 - val_acc: 1.0000\n",
      "Epoch 16/30\n",
      "436/436 [==============================] - 0s 65us/sample - loss: 250560.9670 - acc: 1.0000 - val_loss: 257145.4219 - val_acc: 1.0000\n",
      "Epoch 17/30\n",
      "436/436 [==============================] - 0s 64us/sample - loss: 250560.9746 - acc: 1.0000 - val_loss: 257145.4062 - val_acc: 1.0000\n",
      "Epoch 18/30\n",
      "436/436 [==============================] - 0s 64us/sample - loss: 250560.9576 - acc: 1.0000 - val_loss: 257145.4219 - val_acc: 1.0000\n",
      "Epoch 19/30\n",
      "436/436 [==============================] - 0s 62us/sample - loss: 250560.9613 - acc: 1.0000 - val_loss: 257145.4062 - val_acc: 1.0000\n",
      "Epoch 20/30\n",
      "436/436 [==============================] - 0s 61us/sample - loss: 250560.9644 - acc: 1.0000 - val_loss: 257145.4219 - val_acc: 1.0000\n",
      "Epoch 21/30\n",
      "436/436 [==============================] - 0s 60us/sample - loss: 250560.9806 - acc: 1.0000 - val_loss: 257145.4219 - val_acc: 1.0000\n",
      "Epoch 22/30\n",
      "436/436 [==============================] - 0s 62us/sample - loss: 250560.9597 - acc: 1.0000 - val_loss: 257145.4062 - val_acc: 1.0000\n",
      "Epoch 23/30\n",
      "436/436 [==============================] - 0s 58us/sample - loss: 250560.9669 - acc: 1.0000 - val_loss: 257145.4062 - val_acc: 1.0000\n",
      "Epoch 24/30\n",
      "436/436 [==============================] - 0s 63us/sample - loss: 250560.9513 - acc: 1.0000 - val_loss: 257145.4062 - val_acc: 1.0000\n",
      "Epoch 25/30\n",
      "436/436 [==============================] - 0s 64us/sample - loss: 250560.9793 - acc: 0.9977 - val_loss: 257145.4062 - val_acc: 1.0000\n",
      "Epoch 26/30\n",
      "436/436 [==============================] - 0s 62us/sample - loss: 250560.9626 - acc: 1.0000 - val_loss: 257145.4219 - val_acc: 1.0000\n",
      "Epoch 27/30\n",
      "436/436 [==============================] - 0s 68us/sample - loss: 250560.9492 - acc: 1.0000 - val_loss: 257145.4062 - val_acc: 1.0000\n",
      "Epoch 28/30\n",
      "436/436 [==============================] - 0s 79us/sample - loss: 250560.9614 - acc: 1.0000 - val_loss: 257145.4062 - val_acc: 1.0000\n",
      "Epoch 29/30\n",
      "436/436 [==============================] - 0s 68us/sample - loss: 250560.9538 - acc: 1.0000 - val_loss: 257145.4219 - val_acc: 1.0000\n",
      "Epoch 30/30\n",
      "436/436 [==============================] - 0s 58us/sample - loss: 250560.9533 - acc: 1.0000 - val_loss: 257145.4062 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcd373058d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 50\n",
    "epochs = 30\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 245922.33763586957\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sensitivity] *",
   "language": "python",
   "name": "conda-env-sensitivity-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
