{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Pb-Pb-2760 main calculations from model_calculations/production_500pts_Pb_Pb_2760/Obs/main.dat\n",
      "WARNING! can not load model design calculations\n",
      "Loading Pb-Pb-2760 MAP calculations from model_calculations/MAP/Grad/Obs/obs_Pb-Pb-2760.dat\n",
      "No MAP calculations found for system Pb-Pb-2760\n",
      "Loading Au-Au-200 main calculations from model_calculations/production_500pts_Au_Au_200/Obs/main.dat\n",
      "WARNING! can not load model design calculations\n",
      "Loading Au-Au-200 MAP calculations from model_calculations/MAP/Grad/Obs/obs_Au-Au-200.dat\n",
      "No MAP calculations found for system Au-Au-200\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "sns.set()\n",
    "import sys\n",
    "from numpy.linalg import inv\n",
    "# Provide the path to the sims emulator validation source code base.\n",
    "sys.path.insert(0, '/Users/dananjayaliyanage/git/emulator-validation/src')\n",
    "#sys.path.insert(0, '/Users/dananjayaliyanage/git/emulator-validation/emulator')\n",
    "from configurations import load_design, transform_design\n",
    "#from bayes_mcmc import *\n",
    "from emulator import *\n",
    "from calculations_load import trimmed_model_data,validation_data\n",
    "from bins_and_cuts import *\n",
    "import matplotlib.patches as mpatches\n",
    "#from bayes_exp import Y_exp_data\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/derek/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/derek/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/derek/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/derek/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/derek/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/derek/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/derek/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all model parametr names to an array\n",
    "\n",
    "model_labels= ['norm','trento_p','sigma_k','nucleon_width',\n",
    "               'dmin3','tau_R','alpha','shear_relax_time_factor','Tswitch']\n",
    "\n",
    "viscous_eta=[r'$\\eta \\,$ at T={} GeV'.format(round(i,2)) \n",
    "             for i in np.linspace(0.135,0.4,10)]\n",
    "\n",
    "viscous_bulk=[r'$\\zeta \\,$ at T={} GeV'.format(round(i,2))\n",
    "              for i in np.linspace(0.135,0.4,10)]\n",
    "\n",
    "all_model_labels=model_labels+viscous_eta+viscous_bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the observables list\n",
    "\n",
    "nobs        =  0\n",
    "observables =  []\n",
    "obs_name    =  []\n",
    "\n",
    "for obs, cent_list in obs_cent_list['Pb-Pb-2760'].items():\n",
    "    observables.append(obs)\n",
    "    n = np.array(cent_list).shape[0]\n",
    "    for i in cent_list:\n",
    "        obs_name.append(f'{obs}_{i}')\n",
    "    #self._slices[obs] = slice(self.nobs, self.nobs + n)\n",
    "    nobs += n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Pb-Pb-2760'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-67b6c5d47b4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0midf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mY\u001b[0m   \u001b[0;34m=\u001b[0m  \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mipt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrimmed_model_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Pb-Pb-2760'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mobs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobservables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Pb-Pb-2760'"
     ]
    }
   ],
   "source": [
    "# Get the simulation results corresponding to design points\n",
    "idf=0\n",
    "Y   =  []\n",
    "for ipt, data in enumerate(trimmed_model_data['Pb-Pb-2760']):\n",
    "    row = np.array([])\n",
    "    for obs in observables:\n",
    "        values = np.array(data[idf][obs]['mean'])\n",
    "        if np.isnan(values).sum() > 0:\n",
    "            print(\"WARNING! FOUND NAN IN MODEL DATA WHILE BUILDING EMULATOR!\")\n",
    "            print(\"Design pt = \" + str(pt) + \"; Obs = \" + obs)\n",
    "        row = np.append(row, values)\n",
    "    Y.append(row)\n",
    "Y = np.array(Y)\n",
    "print(\"Y_Obs shape[Ndesign, Nobs] = \" + str(Y.shape))\n",
    "#pca = PCA(copy=False, whiten=True, svd_solver='full')\n",
    "#Z=pca.fit_transform(SS.fit_transform(Y))[:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading main points from production_designs/500pts/design_pts_Pb_Pb_2760_production/design_points_main_PbPb-2760.dat\n",
      "Loading main ranges from production_designs/500pts/design_pts_Pb_Pb_2760_production/design_ranges_main_PbPb-2760.dat\n",
      "Summary of design : \n",
      "Note : Transforming design of viscosities\n",
      "Warning! Deleting 15 points from data\n"
     ]
    }
   ],
   "source": [
    "design, design_max, design_min, labels = prepare_emu_design('Pb-Pb-2760')\n",
    "if len(delete_design_pts_set) > 0:\n",
    "    print(\"Warning! Deleting \"\n",
    "          + str(len(delete_design_pts_set)) + \" points from data\")\n",
    "    design = np.delete(design, list(delete_design_pts_set), 0)\n",
    "alldesign=[design, design_max, design_min,labels]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! FOUND NAN IN MODEL DATA WHILE BUILDING EMULATOR!\n",
      "Design pt = 36; Obs = v42\n",
      "WARNING! FOUND NAN IN MODEL DATA WHILE BUILDING EMULATOR!\n",
      "Design pt = 43; Obs = v42\n",
      "WARNING! FOUND NAN IN MODEL DATA WHILE BUILDING EMULATOR!\n",
      "Design pt = 47; Obs = v42\n",
      "WARNING! FOUND NAN IN MODEL DATA WHILE BUILDING EMULATOR!\n",
      "Design pt = 73; Obs = v42\n",
      "WARNING! FOUND NAN IN MODEL DATA WHILE BUILDING EMULATOR!\n",
      "Design pt = 96; Obs = v42\n",
      "Y_Val_Obs shape[Ndesign, Nobs] = (100, 123)\n"
     ]
    }
   ],
   "source": [
    "# Get the simulation results for validaton corresponding to design points\n",
    "YV=[]\n",
    "nanrows=[]\n",
    "for ipt, data in enumerate(validation_data['Pb-Pb-2760']):\n",
    "    row = np.array([])\n",
    "    for obs in observables:\n",
    "        values = np.array(data[idf][obs]['mean'])\n",
    "        if np.isnan(values).sum() > 0:\n",
    "            print(\"WARNING! FOUND NAN IN MODEL DATA WHILE BUILDING EMULATOR!\")\n",
    "            print(\"Design pt = \" + str(ipt) + \"; Obs = \" + obs)\n",
    "            nanrows.append(ipt)\n",
    "        row = np.append(row, values)\n",
    "    YV.append(row)\n",
    "YV = np.array(YV)\n",
    "nanrows=np.array(nanrows)\n",
    "print(\"Y_Val_Obs shape[Ndesign, Nobs] = \" + str(YV.shape))\n",
    "#pca = PCA(copy=False, whiten=True, svd_solver='full')\n",
    "#Z=pca.fit_transform(SS.fit_transform(Y))[:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "todeleterows=np.concatenate((nanrows,delete_design_pts_validation_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([36, 43, 47, 73, 96, 10, 68, 93])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "todeleterows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 123)\n",
      "after truccation shape(92, 123)\n"
     ]
    }
   ],
   "source": [
    "print(YV.shape)\n",
    "YV_truncates=np.delete(YV,obj=todeleterows,axis=0)\n",
    "print(f'after truccation shape{YV_truncates.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation points from production_designs/500pts/design_pts_Pb_Pb_2760_production/design_points_validation_PbPb-2760.dat\n",
      "Loading validation ranges from production_designs/500pts/design_pts_Pb_Pb_2760_production//design_ranges_validation_PbPb-2760.dat\n",
      "Summary of design : \n",
      "Warning! Deleting 8 points from data\n",
      "Shape of validation design array (92, 17)\n"
     ]
    }
   ],
   "source": [
    "design_v,dsgn_max_v,dsgn_min_v,design_v_lbls=load_design(system_str='Pb-Pb-2760', pset='validation')\n",
    "if len(todeleterows) > 0:\n",
    "    print(\"Warning! Deleting \" + str(len(todeleterows)) + \" points from data\")\n",
    "    design_v= np.delete(np.array(design_v), obj=todeleterows, axis=0)\n",
    "    print(f'Shape of validation design array {design_v.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_v=transform_design(design_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model / data parametaers\n",
    "#num_classes = 10\n",
    "input_shape = (29,1)\n",
    "#x_train= design.reshape(485,29,1)\n",
    "#y_train= Y\n",
    "#x_test=design_v.reshape(92,29,1)\n",
    "#y_test=YV_truncates\n",
    "# the data, split between train and test sets\n",
    "#(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (485, 29, 1)\n",
      "485 train samples\n",
      "92 test samples\n"
     ]
    }
   ],
   "source": [
    "# Scale images to the [0, 1] range\n",
    "#x_train = x_train.astype(\"float32\") / 255\n",
    "#x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "#x_train = np.expand_dims(x_train, -1)\n",
    "#x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "#y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The added layer must be an instance of class Layer. Found: Tensor(\"input_1:0\", shape=(?, 29, 1), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d70bdf80227f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     ]\n\u001b[1;32m     12\u001b[0m )\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/training/checkpointable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m       \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, name)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/training/checkpointable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m       \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    143\u001b[0m       raise TypeError('The added layer must be '\n\u001b[1;32m    144\u001b[0m                       \u001b[0;34m'an instance of class Layer. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                       'Found: ' + str(layer))\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: The added layer must be an instance of class Layer. Found: Tensor(\"input_1:0\", shape=(?, 29, 1), dtype=float32)"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv1D(100, kernel_size=3, activation=\"relu\"),\n",
    "        layers.MaxPooling1D(pool_size=3),\n",
    "        layers.Conv1D(50, kernel_size=3, activation=\"relu\"),\n",
    "        layers.MaxPooling1D(pool_size=3),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(123, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 436 samples, validate on 49 samples\n",
      "Epoch 1/30\n",
      "436/436 [==============================] - 0s 566us/sample - loss: 250587.4243 - acc: 0.0528 - val_loss: 257169.6562 - val_acc: 0.0000e+00\n",
      "Epoch 2/30\n",
      "436/436 [==============================] - 0s 88us/sample - loss: 250581.7577 - acc: 0.1284 - val_loss: 257159.9531 - val_acc: 0.0000e+00\n",
      "Epoch 3/30\n",
      "436/436 [==============================] - 0s 70us/sample - loss: 250571.9258 - acc: 0.4495 - val_loss: 257147.2812 - val_acc: 1.0000\n",
      "Epoch 4/30\n",
      "436/436 [==============================] - 0s 66us/sample - loss: 250563.5461 - acc: 0.8922 - val_loss: 257145.4219 - val_acc: 1.0000\n",
      "Epoch 5/30\n",
      "436/436 [==============================] - 0s 73us/sample - loss: 250561.4269 - acc: 0.9885 - val_loss: 257145.4219 - val_acc: 1.0000\n",
      "Epoch 6/30\n",
      "436/436 [==============================] - 0s 62us/sample - loss: 250561.0664 - acc: 1.0000 - val_loss: 257145.4062 - val_acc: 1.0000\n",
      "Epoch 7/30\n",
      "436/436 [==============================] - 0s 65us/sample - loss: 250561.0007 - acc: 1.0000 - val_loss: 257145.4219 - val_acc: 1.0000\n",
      "Epoch 8/30\n",
      "436/436 [==============================] - 0s 71us/sample - loss: 250561.0011 - acc: 0.9977 - val_loss: 257145.4062 - val_acc: 1.0000\n",
      "Epoch 9/30\n",
      "436/436 [==============================] - 0s 61us/sample - loss: 250560.9805 - acc: 1.0000 - val_loss: 257145.4062 - val_acc: 1.0000\n",
      "Epoch 10/30\n",
      "436/436 [==============================] - 0s 63us/sample - loss: 250560.9962 - acc: 0.9977 - val_loss: 257145.4219 - val_acc: 1.0000\n",
      "Epoch 11/30\n",
      "436/436 [==============================] - 0s 64us/sample - loss: 250560.9731 - acc: 1.0000 - val_loss: 257145.4062 - val_acc: 1.0000\n",
      "Epoch 12/30\n",
      "436/436 [==============================] - 0s 61us/sample - loss: 250560.9911 - acc: 1.0000 - val_loss: 257145.4219 - val_acc: 1.0000\n",
      "Epoch 13/30\n",
      "436/436 [==============================] - 0s 60us/sample - loss: 250560.9705 - acc: 1.0000 - val_loss: 257145.4219 - val_acc: 1.0000\n",
      "Epoch 14/30\n",
      "436/436 [==============================] - 0s 61us/sample - loss: 250560.9674 - acc: 1.0000 - val_loss: 257145.4062 - val_acc: 1.0000\n",
      "Epoch 15/30\n",
      "436/436 [==============================] - 0s 60us/sample - loss: 250560.9612 - acc: 1.0000 - val_loss: 257145.4219 - val_acc: 1.0000\n",
      "Epoch 16/30\n",
      "436/436 [==============================] - 0s 65us/sample - loss: 250560.9670 - acc: 1.0000 - val_loss: 257145.4219 - val_acc: 1.0000\n",
      "Epoch 17/30\n",
      "436/436 [==============================] - 0s 64us/sample - loss: 250560.9746 - acc: 1.0000 - val_loss: 257145.4062 - val_acc: 1.0000\n",
      "Epoch 18/30\n",
      "436/436 [==============================] - 0s 64us/sample - loss: 250560.9576 - acc: 1.0000 - val_loss: 257145.4219 - val_acc: 1.0000\n",
      "Epoch 19/30\n",
      "436/436 [==============================] - 0s 62us/sample - loss: 250560.9613 - acc: 1.0000 - val_loss: 257145.4062 - val_acc: 1.0000\n",
      "Epoch 20/30\n",
      "436/436 [==============================] - 0s 61us/sample - loss: 250560.9644 - acc: 1.0000 - val_loss: 257145.4219 - val_acc: 1.0000\n",
      "Epoch 21/30\n",
      "436/436 [==============================] - 0s 60us/sample - loss: 250560.9806 - acc: 1.0000 - val_loss: 257145.4219 - val_acc: 1.0000\n",
      "Epoch 22/30\n",
      "436/436 [==============================] - 0s 62us/sample - loss: 250560.9597 - acc: 1.0000 - val_loss: 257145.4062 - val_acc: 1.0000\n",
      "Epoch 23/30\n",
      "436/436 [==============================] - 0s 58us/sample - loss: 250560.9669 - acc: 1.0000 - val_loss: 257145.4062 - val_acc: 1.0000\n",
      "Epoch 24/30\n",
      "436/436 [==============================] - 0s 63us/sample - loss: 250560.9513 - acc: 1.0000 - val_loss: 257145.4062 - val_acc: 1.0000\n",
      "Epoch 25/30\n",
      "436/436 [==============================] - 0s 64us/sample - loss: 250560.9793 - acc: 0.9977 - val_loss: 257145.4062 - val_acc: 1.0000\n",
      "Epoch 26/30\n",
      "436/436 [==============================] - 0s 62us/sample - loss: 250560.9626 - acc: 1.0000 - val_loss: 257145.4219 - val_acc: 1.0000\n",
      "Epoch 27/30\n",
      "436/436 [==============================] - 0s 68us/sample - loss: 250560.9492 - acc: 1.0000 - val_loss: 257145.4062 - val_acc: 1.0000\n",
      "Epoch 28/30\n",
      "436/436 [==============================] - 0s 79us/sample - loss: 250560.9614 - acc: 1.0000 - val_loss: 257145.4062 - val_acc: 1.0000\n",
      "Epoch 29/30\n",
      "436/436 [==============================] - 0s 68us/sample - loss: 250560.9538 - acc: 1.0000 - val_loss: 257145.4219 - val_acc: 1.0000\n",
      "Epoch 30/30\n",
      "436/436 [==============================] - 0s 58us/sample - loss: 250560.9533 - acc: 1.0000 - val_loss: 257145.4062 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcd373058d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 50\n",
    "epochs = 30\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 245922.33763586957\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
